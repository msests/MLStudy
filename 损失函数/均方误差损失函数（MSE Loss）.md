## 概述

均方误差是机器学习中用于评估回归模型性能的一种常见损失函数。它通过计算预测值与实际值之间差的平方的平均值来量化模型预测的准确性。

## 关于均方差

设有一组预测值 $\{\hat{y}_1, \hat{y}_2, \ldots, \hat{y}_n\}$ 和对应的实际值 $\{y_1, y_2, \ldots, y_n\}$，其中 $n$ 表示样本数量。则均方误差（MSE）定义为：
$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2
$$
这里，$(\hat{y}_i - y_i)$ 表示第 $i$ 个样本的预测误差，而 $(\hat{y}_i - y_i)^2$ 则表示该误差的平方。求和后除以样本数量 $n$ 得到所有样本的平均误差平方。

## 均方误差损失函数的求导与梯度更新

均方误差损失函数通常用于回归问题，其定义为：
$$
L(y, \hat{y}) = \frac{1}{2} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$
其中，$y_i$ 是真实值，$\hat{y}_i$ 是预测值。为了进行梯度更新，我们需要对损失函数关于模型的参数求导。这里假设模型的预测值 $\hat{y}_i$ 是通过线性组合 $w^Tx_i + b$ 得到的，其中 $w$ 是权重向量，$x_i$ 是输入特征向量，$b$ 是偏置项。

### 对于权重 $w$ 的导数

考虑到链式法则，MSE 损失函数对权重 $w$ 的导数可以表示为：
$$
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w}
$$
由于 $\hat{y}_i = w^Tx_i + b$，因此有：
$$
\frac{\partial \hat{y}_i}{\partial w} = x_i
$$
而 $\frac{\partial L}{\partial \hat{y}_i} = -(y_i - \hat{y}_i)$，因此：
$$
\frac{\partial L}{\partial w} = -\sum_{i=1}^{n} (y_i - \hat{y}_i) \cdot x_i
$$
注意到在实际应用中，我们通常去掉负号来使得梯度下降朝着减少损失的方向前进，所以最终的形式为：
$$
\frac{\partial L}{\partial w} = \sum_{i=1}^{n} (\hat{y}_i - y_i) \cdot x_i
$$
### 对于偏置 $b$ 的导数

类似地，对于偏置项 $b$，我们有：

$$
\frac{\partial L}{\partial b} = \sum_{i=1}^{n} (\hat{y}_i - y_i)
$$

### 参数更新规则

基于梯度下降法，参数的更新规则为：
$$
w := w - \alpha \frac{\partial L}{\partial w}
$$
$$
b := b - \alpha \frac{\partial L}{\partial b}
$$
其中，$\alpha$ 代表学习率。

## 优点

- **易于理解**：MSE 的概念直观易懂，便于解释。
- **数学性质良好**：由于其基于平方，MSE 在数学上处理起来比较方便，尤其是在推导公式和优化算法时。
- **强调大误差**：由于采用平方的方式放大了较大误差的影响，使得MSE对异常值较为敏感，有助于在训练过程中更关注这些大误差情况。

## 缺点

- **对异常值敏感**：虽然放大较大的误差可以帮助我们发现异常值，但这同时也是MSE的一个缺点。一个异常值就可以导致MSE显著增加，从而可能误导模型的学习过程。
- **单位不一致**：MSE的结果是误差的平方，这意味着它的单位是原数据单位的平方，这有时可能会造成理解上的不便。例如，如果目标变量的单位是米（m），那么MSE的单位就是平方米（$m^2$），这与原始数据的尺度不同。